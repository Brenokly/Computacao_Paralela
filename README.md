Claro, pe√ßo desculpas por qualquer problema na formata√ß√£o anterior.

Aqui est√° o conte√∫do completo e atualizado para o seu arquivo `README.md`. Ele est√° no formato Markdown, pronto para ser copiado e colado diretamente no GitHub.

```markdown
# üêç Implementa√ß√£o e Avalia√ß√£o de Programas Paralelos usando C++, Kotlin e Python üöÄ

**Curso:** Ci√™ncia da Computa√ß√£o üíª  
**Universidade:** UFERSA - Universidade Federal Rural do Semi-√Årido üå±  
**Status:** Pesquisa Conclu√≠da ‚úÖ

**Autores:**
* **Discente:** Breno Klywer Olegario de Moura
* **Orientador:** Paulo Henrique Lopes Silva

[cite_start]Este reposit√≥rio documenta a pesquisa e os resultados do artigo **"Implementa√ß√£o e Avalia√ß√£o de Programas Paralelos usando C++, Kotlin e Python"** [cite: 1][cite_start], que realiza uma an√°lise comparativa de desempenho entre as tr√™s linguagens na paraleliza√ß√£o de algoritmos cl√°ssicos[cite: 4].

## üìö Resumo da Pesquisa

[cite_start]A computa√ß√£o paralela √© fundamental para extrair o m√°ximo de desempenho de processadores multicore[cite: 2]. [cite_start]A escolha da linguagem e do paradigma de programa√ß√£o, no entanto, impacta diretamente a efici√™ncia, a escalabilidade e a complexidade do desenvolvimento[cite: 3].

[cite_start]Este estudo apresenta uma an√°lise de desempenho comparativa da paraleliza√ß√£o do **Quicksort** e da **Multiplica√ß√£o de Matrizes** utilizando C++, Kotlin e Python[cite: 4].

* [cite_start]Em **C++**, exploramos o paralelismo nativo com `std::async`[cite: 5].
* [cite_start]Em **Kotlin**, utilizamos corrotinas sobre a JVM para obter paralelismo gerenciado[cite: 5].
* [cite_start]Em **Python**, avaliamos o `ThreadPoolExecutor` (limitado pelo I/O) e a biblioteca `multiprocessing` para contornar o Global Interpreter Lock (GIL) em tarefas de uso intensivo da CPU[cite: 6].

## üéØ Objetivos Atingidos

* [cite_start]**Avalia√ß√£o Emp√≠rica Rigorosa:** Medimos o desempenho e a escalabilidade das implementa√ß√µes em hardware de commodity (AMD Ryzen 5 5600G, 6 n√∫cleos/12 threads)[cite: 21, 37].
* [cite_start]**An√°lise de Gargalos:** Investigamos o impacto do GIL em Python, os custos de comunica√ß√£o entre processos (IPC) e a efici√™ncia dos modelos de agendamento de tarefas de cada ecossistema[cite: 23].
* [cite_start]**Identifica√ß√£o de Pontos Cr√≠ticos:** Demonstramos quantitativamente o "ponto de inflex√£o" (`maxDepth` √≥timo) onde o overhead de cria√ß√£o de threads em C++ supera os ganhos do paralelismo e o risco de deadlock em implementa√ß√µes recursivas com `ThreadPoolExecutor` em Python[cite: 8, 22].

## üõ†Ô∏è Metodologia

A avalia√ß√£o foi conduzida sob uma metodologia de benchmark rigorosa para garantir a validade estat√≠stica.

1.  **Ambiente de Teste:**
    * [cite_start]**CPU:** AMD Ryzen 5 5600G (6 N√∫cleos, 12 Threads) @ 3.9GHz [cite: 37]
    * [cite_start]**RAM:** 16 GB DDR4 [cite: 37]
    * [cite_start]**SO:** Windows 11 Pro 24H2 [cite: 37]
    * [cite_start]**Vers√µes:** C++17 (MSVC v19.38), Kotlin 2.0.0 (JVM 23), Python 3.13.3[cite: 37].
2.  [cite_start]**Processo de Benchmark:** Para cada teste, realizamos 3 execu√ß√µes de aquecimento (descartadas) seguidas de 7 medi√ß√µes independentes[cite: 39, 40]. [cite_start]Os resultados apresentados s√£o a m√©dia e o desvio padr√£o dessas medi√ß√µes[cite: 41].
3.  **M√©tricas:**
    * [cite_start]**Tempo de Execu√ß√£o (s):** M√©dia das execu√ß√µes[cite: 50].
    * [cite_start]**Speedup:** Raz√£o entre o tempo de execu√ß√£o sequencial e o paralelo ($T_{sequencial}/T_{paralelo}$)[cite: 51].

## üìä Resultados e An√°lise

### Quicksort Paralelo

[cite_start]O paralelismo foi aplicado de forma recursiva, com a profundidade controlada pelo par√¢metro `maxDepth`[cite: 43].

* [cite_start]**C++:** Foi a linguagem mais perform√°tica, atingindo um **speedup de at√© 3.39x**[cite: 65, 66]. [cite_start]O desempenho √© sens√≠vel ao `maxDepth`, com o ponto √≥timo variando conforme o tamanho da entrada, revelando que o overhead de cria√ß√£o de threads se torna um gargalo ap√≥s certa profundidade[cite: 57].
* [cite_start]**Kotlin:** Apresentou um *slowdown* (speedup < 1.0x), indicando que o overhead do gerenciamento de tarefas superou os ganhos do paralelismo[cite: 67]. [cite_start]No entanto, seu scheduler se mostrou robusto e est√°vel, sem travar com o aumento da recurs√£o[cite: 58].
* [cite_start]**Python (`ThreadPoolExecutor`):** Al√©m do *slowdown* devido ao GIL [cite: 68][cite_start], a implementa√ß√£o **travou (deadlock) a partir de `maxDepth=5`** [cite: 56, 59][cite_start], confirmando que `ThreadPoolExecutor` √© vulner√°vel e inadequado para algoritmos recursivos com paralelismo[cite: 59, 82].

| Linguagem | Tamanho (N) | Tempo Sequencial (s) | Melhor Tempo Paralelo (s) | Speedup |
| :--- | :--- | :--- | :--- | :--- |
| **C++** | 5.000.000 | 0.3589 | **0.1057** (d=8) | **3.39x** |
| **Kotlin**| 5.000.000 | 0.4808 | 0.5151 (d=4) | 0.93x |
| **Python**| 5.000.000 | 20.5430 | 21.2038 (d=2)| 0.97x |

[cite_start]*(Tabela adaptada da Tabela 2 do artigo [cite: 63, 65])*

### Multiplica√ß√£o de Matrizes Paralela

[cite_start]Nesta tarefa, onde o c√°lculo de cada linha da matriz resultante foi distribu√≠do[cite: 48], os resultados foram distintos.

* [cite_start]**Kotlin:** Demonstrou **excelente escalabilidade**, com o speedup crescendo com o tamanho da matriz, atingindo um pico de **5.82x**[cite: 71, 72]. [cite_start]Isso confirma a efici√™ncia do modelo de corrotinas e da JVM para tarefas "embara√ßosamente paralelas"[cite: 69, 72].
* [cite_start]**Python (`multiprocessing`):** Apresentou um *slowdown* dr√°stico e consistente[cite: 73]. [cite_start]O custo de serializa√ß√£o e comunica√ß√£o entre processos (IPC) para transferir as sub-matrizes foi t√£o alto que anulou completamente os ganhos obtidos com o paralelismo[cite: 73].

| Linguagem | Tamanho da Matriz (NxN) | Tempo Sequencial (s) | Tempo Paralelo (s) | Speedup |
| :--- | :--- | :--- | :--- | :--- |
| **Kotlin**| 1473 | 10.6651 | **1.8342** | **5.82x** |
| **Python**| 1473 | 0.0666 | 0.6225 | 0.11x |

[cite_start]*(Tabela adaptada da Tabela 3 do artigo [cite: 70, 71])*

## üéì Conclus√µes

1.  [cite_start]**C++:** Oferece o **melhor desempenho absoluto**, mas exige gerenciamento manual e sintonia fina (`maxDepth`) para evitar que o overhead de cria√ß√£o de threads degrade a performance[cite: 77, 78, 86].
2.  [cite_start]**Kotlin:** Provou ser uma **alternativa robusta e de alta produtividade**[cite: 9]. [cite_start]Seu modelo de corrotinas com um scheduler inteligente se mostrou resiliente, escal√°vel e eficiente, destacando-se como uma excelente op√ß√£o para paralelismo na JVM[cite: 79, 80, 86].
3.  [cite_start]**Python:** As bibliotecas padr√£o (`ThreadPoolExecutor`, `multiprocessing`) s√£o **inadequadas para paralelismo de CPU de alta performance**[cite: 9, 87]. [cite_start]O `ThreadPoolExecutor` √© ineficaz pelo GIL e arriscado em cen√°rios recursivos[cite: 82]. [cite_start]O `multiprocessing` sofre com um overhead de IPC que o torna invi√°vel para tarefas com comunica√ß√£o de dados frequente[cite: 83].

## üîÆ Trabalhos Futuros

* [cite_start]Comparar os resultados com bibliotecas padr√£o da ind√∫stria, como **OpenMP** (para C++) e **Numba** (para Python)[cite: 88].
* [cite_start]Desenvolver um modelo heur√≠stico para prever o `maxDepth` √≥timo para o Quicksort com base em par√¢metros de hardware e tamanho da entrada[cite: 89].

## üìë Refer√™ncia Principal

> Moura, B. K. O. de, & Silva, P. H. L. (2024). *Implementa√ß√£o e Avalia√ß√£o de Programas Paralelos usando C++, Kotlin e Python*. [cite_start]Departamento de Computa√ß√£o, Universidade Federal Rural do Semi-√Årido (UFERSA). [cite: 1]

```
