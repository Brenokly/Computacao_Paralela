# ğŸ ImplementaÃ§Ã£o e AvaliaÃ§Ã£o de Programas Paralelos usando C++, Kotlin e Python ğŸš€

**Curso:** CiÃªncia da ComputaÃ§Ã£o ğŸ’»  
**Universidade:** UFERSA - Universidade Federal Rural do Semi-Ãrido ğŸŒ±  
**Status:** Pesquisa ConcluÃ­da âœ…

**Autores:**
* **Discente:** Breno Klywer Olegario de Moura
* **Orientador:** Paulo Henrique Lopes Silva

[cite_start]Este repositÃ³rio documenta a pesquisa e os resultados do artigo **"ImplementaÃ§Ã£o e AvaliaÃ§Ã£o de Programas Paralelos usando C++, Kotlin e Python"** [cite: 1][cite_start], que realiza uma anÃ¡lise comparativa de desempenho entre as trÃªs linguagens na paralelizaÃ§Ã£o de algoritmos clÃ¡ssicos[cite: 4].

## ğŸ“š Resumo da Pesquisa

[cite_start]A computaÃ§Ã£o paralela Ã© fundamental para extrair o mÃ¡ximo de desempenho de processadores multicore[cite: 2]. [cite_start]A escolha da linguagem e do paradigma de programaÃ§Ã£o, no entanto, impacta diretamente a eficiÃªncia, a escalabilidade e a complexidade do desenvolvimento[cite: 3].

[cite_start]Este estudo apresenta uma anÃ¡lise de desempenho comparativa da paralelizaÃ§Ã£o do **Quicksort** e da **MultiplicaÃ§Ã£o de Matrizes** utilizando C++, Kotlin e Python[cite: 4].

* [cite_start]Em **C++**, exploramos o paralelismo nativo com `std::async`[cite: 5].
* [cite_start]Em **Kotlin**, utilizamos corrotinas sobre a JVM para obter paralelismo gerenciado[cite: 5].
* [cite_start]Em **Python**, avaliamos o `ThreadPoolExecutor` (limitado pelo I/O) e a biblioteca `multiprocessing` para contornar o Global Interpreter Lock (GIL) em tarefas de uso intensivo da CPU[cite: 6].

## ğŸ¯ Objetivos Atingidos

* [cite_start]**AvaliaÃ§Ã£o EmpÃ­rica Rigorosa:** Medimos o desempenho e a escalabilidade das implementaÃ§Ãµes em hardware de commodity (AMD Ryzen 5 5600G, 6 nÃºcleos/12 threads)[cite: 21, 37].
* [cite_start]**AnÃ¡lise de Gargalos:** Investigamos o impacto do GIL em Python, os custos de comunicaÃ§Ã£o entre processos (IPC) e a eficiÃªncia dos modelos de agendamento de tarefas de cada ecossistema[cite: 23].
* [cite_start]**IdentificaÃ§Ã£o de Pontos CrÃ­ticos:** Demonstramos quantitativamente o "ponto de inflexÃ£o" (`maxDepth` Ã³timo) onde o overhead de criaÃ§Ã£o de threads em C++ supera os ganhos do paralelismo e o risco de deadlock em implementaÃ§Ãµes recursivas com `ThreadPoolExecutor` em Python[cite: 8, 22].

## ğŸ› ï¸ Metodologia

A avaliaÃ§Ã£o foi conduzida sob uma metodologia de benchmark rigorosa para garantir a validade estatÃ­stica.

1.  **Ambiente de Teste:**
    * [cite_start]**CPU:** AMD Ryzen 5 5600G (6 NÃºcleos, 12 Threads) @ 3.9GHz [cite: 37]
    * [cite_start]**RAM:** 16 GB DDR4 [cite: 37]
    * [cite_start]**SO:** Windows 11 Pro 24H2 [cite: 37]
    * [cite_start]**VersÃµes:** C++17 (MSVC v19.38), Kotlin 2.0.0 (JVM 23), Python 3.13.3[cite: 37].
2.  [cite_start]**Processo de Benchmark:** Para cada teste, realizamos 3 execuÃ§Ãµes de aquecimento (descartadas) seguidas de 7 mediÃ§Ãµes independentes[cite: 39, 40]. [cite_start]Os resultados apresentados sÃ£o a mÃ©dia e o desvio padrÃ£o dessas mediÃ§Ãµes[cite: 41].
3.  **MÃ©tricas:**
    * [cite_start]**Tempo de ExecuÃ§Ã£o (s):** MÃ©dia das execuÃ§Ãµes[cite: 50].
    * [cite_start]**Speedup:** RazÃ£o entre o tempo de execuÃ§Ã£o sequencial e o paralelo ($T_{sequencial}/T_{paralelo}$)[cite: 51].

## ğŸ“Š Resultados e AnÃ¡lise

### Quicksort Paralelo

[cite_start]O paralelismo foi aplicado de forma recursiva, com a profundidade controlada pelo parÃ¢metro `maxDepth`[cite: 43].

* [cite_start]**C++:** Foi a linguagem mais performÃ¡tica, atingindo um **speedup de atÃ© 3.39x**[cite: 65, 66]. [cite_start]O desempenho Ã© sensÃ­vel ao `maxDepth`, com o ponto Ã³timo variando conforme o tamanho da entrada, revelando que o overhead de criaÃ§Ã£o de threads se torna um gargalo apÃ³s certa profundidade[cite: 57].
* [cite_start]**Kotlin:** Apresentou um *slowdown* (speedup < 1.0x), indicando que o overhead do gerenciamento de tarefas superou os ganhos do paralelismo[cite: 67]. [cite_start]No entanto, seu scheduler se mostrou robusto e estÃ¡vel, sem travar com o aumento da recursÃ£o[cite: 58].
* [cite_start]**Python (`ThreadPoolExecutor`):** AlÃ©m do *slowdown* devido ao GIL [cite: 68][cite_start], a implementaÃ§Ã£o **travou (deadlock) a partir de `maxDepth=5`** [cite: 56, 59][cite_start], confirmando que `ThreadPoolExecutor` Ã© vulnerÃ¡vel e inadequado para algoritmos recursivos com paralelismo[cite: 59, 82].

| Linguagem | Tamanho (N) | Tempo Sequencial (s) | Melhor Tempo Paralelo (s) | Speedup |
| :--- | :--- | :--- | :--- | :--- |
| **C++** | 5.000.000 | 0.3589 | **0.1057** (d=8) | **3.39x** |
| **Kotlin**| 5.000.000 | 0.4808 | 0.5151 (d=4) | 0.93x |
| **Python**| 5.000.000 | 20.5430 | 21.2038 (d=2)| 0.97x |

[cite_start]*(Tabela adaptada da Tabela 2 do artigo [cite: 63, 65])*

### MultiplicaÃ§Ã£o de Matrizes Paralela

[cite_start]Nesta tarefa, onde o cÃ¡lculo de cada linha da matriz resultante foi distribuÃ­do[cite: 48], os resultados foram distintos.

* [cite_start]**Kotlin:** Demonstrou **excelente escalabilidade**, com o speedup crescendo com o tamanho da matriz, atingindo um pico de **5.82x**[cite: 71, 72]. [cite_start]Isso confirma a eficiÃªncia do modelo de corrotinas e da JVM para tarefas "embaraÃ§osamente paralelas"[cite: 69, 72].
* [cite_start]**Python (`multiprocessing`):** Apresentou um *slowdown* drÃ¡stico e consistente[cite: 73]. [cite_start]O custo de serializaÃ§Ã£o e comunicaÃ§Ã£o entre processos (IPC) para transferir as sub-matrizes foi tÃ£o alto que anulou completamente os ganhos obtidos com o paralelismo[cite: 73].

| Linguagem | Tamanho da Matriz (NxN) | Tempo Sequencial (s) | Tempo Paralelo (s) | Speedup |
| :--- | :--- | :--- | :--- | :--- |
| **Kotlin**| 1473 | 10.6651 | **1.8342** | **5.82x** |
| **Python**| 1473 | 0.0666 | 0.6225 | 0.11x |

[cite_start]*(Tabela adaptada da Tabela 3 do artigo [cite: 70, 71])*

## ğŸ“ ConclusÃµes

1.  [cite_start]**C++:** Oferece o **melhor desempenho absoluto**, mas exige gerenciamento manual e sintonia fina (`maxDepth`) para evitar que o overhead de criaÃ§Ã£o de threads degrade a performance[cite: 77, 78, 86].
2.  [cite_start]**Kotlin:** Provou ser uma **alternativa robusta e de alta produtividade**[cite: 9]. [cite_start]Seu modelo de corrotinas com um scheduler inteligente se mostrou resiliente, escalÃ¡vel e eficiente, destacando-se como uma excelente opÃ§Ã£o para paralelismo na JVM[cite: 79, 80, 86].
3.  [cite_start]**Python:** As bibliotecas padrÃ£o (`ThreadPoolExecutor`, `multiprocessing`) sÃ£o **inadequadas para paralelismo de CPU de alta performance**[cite: 9, 87]. [cite_start]O `ThreadPoolExecutor` Ã© ineficaz pelo GIL e arriscado em cenÃ¡rios recursivos[cite: 82]. [cite_start]O `multiprocessing` sofre com um overhead de IPC que o torna inviÃ¡vel para tarefas com comunicaÃ§Ã£o de dados frequente[cite: 83].

## ğŸ”® Trabalhos Futuros

* [cite_start]Comparar os resultados com bibliotecas padrÃ£o da indÃºstria, como **OpenMP** (para C++) e **Numba** (para Python)[cite: 88].
* [cite_start]Desenvolver um modelo heurÃ­stico para prever o `maxDepth` Ã³timo para o Quicksort com base em parÃ¢metros de hardware e tamanho da entrada[cite: 89].

## ğŸ“‘ ReferÃªncia Principal

> Moura, B. K. O. de, & Silva, P. H. L. (2024). *ImplementaÃ§Ã£o e AvaliaÃ§Ã£o de Programas Paralelos usando C++, Kotlin e Python*. [cite_start]Departamento de ComputaÃ§Ã£o, Universidade Federal Rural do Semi-Ãrido (UFERSA). [cite: 1]
